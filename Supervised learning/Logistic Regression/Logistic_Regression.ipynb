{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic Regression\n",
    "#### Language: Python 3.8.8\n",
    "#### Author: Tianjian Sun\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "- [Introduction](#Introduction)\n",
    "- [Algorithm](#Algorithm)\n",
    "    - [Model](#Model)\n",
    "    - [Cross-entropy](#Cross-entropy)\n",
    "    - [Gradient Descent in Solving Logistic Regression](#Gradient)\n",
    "- [Illustration](#Illustration)\n",
    "- [Advantages and Disadvantages](#Advantages)\n",
    "    - [Advantages](#Advantages)\n",
    "    - [Disadvantages](#Disadvantages)\n",
    "- [Code of Logistic Regression](#Code)\n",
    "- [Applications on data sets](#Applications)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <a class=\"anchor\" id=\"Introduction\"></a>\n",
    "\n",
    "In statistics, the [logistic regression model](https://en.wikipedia.org/wiki/Logistic_regression) is used to model the probability of a certain class or event existing. This can be extended to model several classes of events. Basicly it's an extension of linear regression to deal with classification tasks.\n",
    "\n",
    "Logistic regression is used in various fields, including machine learning, most medical fields, and social sciences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm <a class=\"anchor\" id=\"Algorithm\"></a>\n",
    "\n",
    "#### Model <a class=\"anchor\" id=\"Model\"></a>\n",
    "Consider a model with two predictors, $x_1$ and $x_2$, and one binary (Bernoulli) response variable $y$, with parameter $p=P(Y=1)$. We assume a linear relationship between the predictor variables and the log-odds (also called logit) of the event that $y=1$. This linear relationship can be written in the following mathematical form :\n",
    "\n",
    "$$\\log \\frac{p}{1-p} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$$\n",
    "\n",
    "where $\\beta_i$ are parameters of the model.\n",
    "\n",
    "We can recover the odds by exponentiating both sides of the above:\n",
    "\n",
    "$$\\frac{p}{1-p} = e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2}$$\n",
    "\n",
    "Isolating $p$ we have that the probability that $y=1$ is\n",
    "\n",
    "$$p = \\frac{e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2}}{e^{\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2} + 1} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)}} = \\sigma(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)$$\n",
    "\n",
    "where $\\sigma(\\cdot)$ is the sigmoid function.\n",
    "\n",
    "\n",
    "#### Cross-entropy <a class=\"anchor\" id=\"Cross-entropy\"></a>\n",
    "Cross-entropy loss is widely used in classification tasks. The [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy) between two probability distributions $p$ and $q$ over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution $q$, rather than the true distribution $p$.\n",
    "\n",
    "For discrete probability distributions, it's given by\n",
    "$$\n",
    "L(p, q) = -\\sum_x {p(x)log (q(x))}\n",
    "$$\n",
    "\n",
    "And for binary classification, the form is\n",
    "$$\n",
    "L(p) = - (y log(p) + (1-y)log(1-p))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent in Solving Logistic Regression <a class=\"anchor\" id=\"Gradient\"></a>\n",
    "\n",
    "To use gradient descent to solve the solution of Logistic Regression, similar with linear regression, we take the derivative of loss function, and update the weights by the algorithm in the **Gradient Descent** section.\n",
    "\n",
    "The loss function is the different part. Here the loss function for binary classification is given by\n",
    "$$\n",
    "L(\\hat{y}, y) = - (y log(\\sigma(\\mathbf{x}\\boldsymbol{\\beta})) + (1-y)log(1-\\sigma(\\mathbf{x}\\boldsymbol{\\beta})))\n",
    "$$\n",
    "\n",
    "Thus the gradient is\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{\\beta}} = [\\sigma(\\mathbf{x}\\boldsymbol{\\beta}-y)]\\mathbf{x}\n",
    "$$\n",
    "\n",
    "And then follow the algorithm in the **Gradient Descent** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Illustration <a class=\"anchor\" id=\"Illustration\"></a>\n",
    "\n",
    "Basicly, rather than using a line to regress numeric values, logistic regression turns a linear regression to a *sigmoid* curve to classify different classes.\n",
    " \n",
    "<img src=\"images/Exam_pass_logistic_curve.jpeg\" alt=\"drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Logistic Regression <a class=\"anchor\" id=\"Advantages\"></a>\n",
    "#### Advantages\n",
    "- Easier to implement, interpret, and very efficient to train.\n",
    "- Running fast\n",
    "- No assumptions about distributions of classes in feature space.\n",
    "- Can use coefficients to interpret feature importance\n",
    "- Can deal with missing data and no need of normalization.\n",
    "- Easy to interprete feature importance\n",
    "\n",
    "#### Disadvantages <a class=\"anchor\" id=\"Disadvantages\"></a>\n",
    "- Assume linear relations\n",
    "- Cannot deal with the situation that number of features is larger than number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Code of Logistic Regression <a class=\"anchor\" id=\"Code\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import necessary packages\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [numpy](https://numpy.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [sklearn](https://scikit-learn.org/stable/datasets/toy_dataset.html)\n",
    "- [seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent_Logit_R():\n",
    "    # initialize\n",
    "    def __init__(self) -> None:\n",
    "        self.X = None\n",
    "        self.variables = None\n",
    "        self.y = None\n",
    "        self.predictor = None\n",
    "        self.n = None\n",
    "        self.p = None\n",
    "        self.bias = None\n",
    "        self.gamma = None\n",
    "        self.max_iter = None\n",
    "        self.eta = None\n",
    "\n",
    "        self.weights = None\n",
    "        self.weights_history = []\n",
    "        self.loss_history = [np.inf]\n",
    "    \n",
    "    # cross entropy loss of one data\n",
    "    def cross_entropy_loss(self, y, y_hat):\n",
    "        return -y*np.log(y_hat) - (1.0-y)*np.log(1.0-y_hat)\n",
    "\n",
    "    # total cross entropy loss\n",
    "    def loss(self):\n",
    "        total_loss = sum(self.cross_entropy_loss(self.y[i], self.sigmoid(x@self.weights)) for i, x in enumerate(self.X))\n",
    "        return total_loss\n",
    "\n",
    "    # sigmoid function\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "    # gradient of loss\n",
    "    def gradient_L(self):\n",
    "        sigmoids = np.array([self.sigmoid(x@self.weights) - self.y[i] for i, x in enumerate(self.X)])\n",
    "        d_w = sigmoids @ self.X\n",
    "        return d_w\n",
    "\n",
    "    # model fitting\n",
    "    def fit(self, X, y, bias=True, gamma=0.01, max_iter=100, eta=0.001):\n",
    "        self.variables = X.columns\n",
    "        self.predictor = y.name\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        if bias:\n",
    "            ones_column = np.ones((X.shape[0], 1))\n",
    "            X = np.append(ones_column, X, axis=1)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.bias = bias\n",
    "        self.gamma = gamma\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "        \n",
    "        weights = np.random.rand(self.p)\n",
    "        self.weights = weights\n",
    "        self.weights_history.append(weights)\n",
    "        for i in range(1, max_iter+1):\n",
    "            dw = self.gradient_L()\n",
    "            weights = weights - gamma * dw\n",
    "            self.weights = weights\n",
    "            self.weights_history.append(weights)\n",
    "            L = self.loss()\n",
    "            self.loss_history.append(L)\n",
    "            if i >= self.max_iter or abs(L - self.loss_history[i-1]) <= self.eta:\n",
    "                break\n",
    "    \n",
    "    # predict new data\n",
    "    def prediction(self, X, weights):\n",
    "        X = X.to_numpy()\n",
    "        if self.bias:\n",
    "            ones_column = np.ones((X.shape[0], 1))\n",
    "            X = np.append(ones_column, X, axis=1)\n",
    "        labels = np.array([1, 0])\n",
    "        y_hat = [self.sigmoid(x @ weights) for x in X]\n",
    "        return [np.random.choice(labels, p = [y_hat_i, 1.0-y_hat_i]) for y_hat_i in y_hat]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Applications on data sets <a class=\"anchor\" id=\"Applications\"></a>\n",
    "\n",
    "* *wine* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test decistion tree on the *wine* data set from *sklearn.datasets*\n",
    "\n",
    "Load *wine* data, and only pick first 2 types of wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "X = X[y!=2]\n",
    "y = y[y!=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the input to avoid dividing by $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.452455</td>\n",
       "      <td>-0.294414</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>-0.940375</td>\n",
       "      <td>1.768686</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.775592</td>\n",
       "      <td>-0.462247</td>\n",
       "      <td>1.000229</td>\n",
       "      <td>0.892384</td>\n",
       "      <td>-0.112428</td>\n",
       "      <td>2.040025</td>\n",
       "      <td>0.782868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289066</td>\n",
       "      <td>-0.214558</td>\n",
       "      <td>-0.677197</td>\n",
       "      <td>-2.239324</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.367386</td>\n",
       "      <td>-0.646296</td>\n",
       "      <td>-0.878867</td>\n",
       "      <td>0.114374</td>\n",
       "      <td>-0.052918</td>\n",
       "      <td>0.941437</td>\n",
       "      <td>0.740152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243886</td>\n",
       "      <td>0.447106</td>\n",
       "      <td>1.113242</td>\n",
       "      <td>-0.054728</td>\n",
       "      <td>0.071792</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>1.020516</td>\n",
       "      <td>-0.278198</td>\n",
       "      <td>1.967684</td>\n",
       "      <td>0.917082</td>\n",
       "      <td>-0.171937</td>\n",
       "      <td>0.455524</td>\n",
       "      <td>1.124598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.610586</td>\n",
       "      <td>-0.020622</td>\n",
       "      <td>0.538951</td>\n",
       "      <td>-0.586117</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>1.360688</td>\n",
       "      <td>-0.830346</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>2.226115</td>\n",
       "      <td>-1.183603</td>\n",
       "      <td>1.047071</td>\n",
       "      <td>1.964684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334246</td>\n",
       "      <td>0.709490</td>\n",
       "      <td>1.788880</td>\n",
       "      <td>0.653789</td>\n",
       "      <td>1.181300</td>\n",
       "      <td>0.510421</td>\n",
       "      <td>0.272138</td>\n",
       "      <td>0.550024</td>\n",
       "      <td>0.125798</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>-0.112428</td>\n",
       "      <td>-0.051517</td>\n",
       "      <td>-0.156889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.452455 -0.294414  0.302478 -0.940375  1.768686  0.510421  0.775592   \n",
       "1  0.289066 -0.214558 -0.677197 -2.239324  0.006527  0.234327  0.367386   \n",
       "2  0.243886  0.447106  1.113242 -0.054728  0.071792  0.510421  1.020516   \n",
       "3  1.610586 -0.020622  0.538951 -0.586117  0.854974  2.443085  1.360688   \n",
       "4  0.334246  0.709490  1.788880  0.653789  1.181300  0.510421  0.272138   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0 -0.462247  1.000229  0.892384 -0.112428  2.040025  0.782868  \n",
       "1 -0.646296 -0.878867  0.114374 -0.052918  0.941437  0.740152  \n",
       "2 -0.278198  1.967684  0.917082 -0.171937  0.455524  1.124598  \n",
       "3 -0.830346  0.795575  2.226115 -1.183603  1.047071  1.964684  \n",
       "4  0.550024  0.125798  0.077326 -0.112428 -0.051517 -0.156889  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(X_scaler.fit_transform(X))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=24)\n",
    "model = gradient_descent_Logit_R()\n",
    "model.fit(X_train, y_train,gamma=0.01, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_history)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data, and check the accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, accuracy score = 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.prediction(X_test, model.weights)\n",
    "print(f'Logistic regression, accuracy score = {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "ax=plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "ax.set_title('Confusion Matrix of Ensemble Model')\n",
    "ax.set_xlabel('predicted label', fontsize=10)\n",
    "ax.set_ylabel('True label', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really excellent prediction accuracy! All test data are correctly classified."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e918aaa81d99c652401bdd1a0c185581595fb477ac919641bd65261b5d7782a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
