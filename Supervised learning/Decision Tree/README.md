# Decision Tree

This repository represents the implementation and applications of decision tree. 

## File descriptions
"Decision_Tree.ipynb" contains the describtion and coding of applications of decision tree algorithm.

Outline:
- Introduction
- Algorithm
    - Steps for creating a decision tree
    - Information Gain (IG)
    - The Formula of Inpurity of a node
        - Entropy
        - Gini Impurity
- Illustration
- Advantages and Disadvantages
    - Advantages
    - Disadvantages
- Code and Applications on data sets
    - Classification problem
    - Regression problem
- Reference

## Dataset used in applications
Both of the *wine* and *boston housing* dataset is loaded from *sklearn.datasets*.
* *wine* dataset 

The *wine* dataset is a classic and very easy multi-class classification dataset. It has 3 classes of target labels, each label has samples of 59, 71, 48, and the total sample size is 178 without any missing value. 

There're 13 features and there're all numeric, real, and positive. These features are Alcohol Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines and Proline.

* quadratic data plus noise data set

The dataset is a man-made data by creating quadratic data plus some noise.

