# Optimization Methods
---
## Table Content
* [Introduction](#Introduction)
* [Algorithms](#Algorithms)
    - [Gradient Descent](#Gradient)
* [Challenges](#Challenges)
* [Reference](#Reference)

---
## Introduction  <a class="anchor" id="Introduction"></a>
**Supervised learning** is a group of machine learning tasks that learn a function that maps an input to an output based on example input-output pairs. 
It infers a function from labeled training data consisting of a set of training examples. 
In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). 
A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. 
An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances.

---
## Algorithms <a class="anchor" id="Algorithms"></a>

Various algorithms and computation techniques are used in supervised machine learning processes. Below are brief explanations of models learned in class:

---
## Challenges <a class="anchor" id="Challenges"></a>
Although supervised learning can offer businesses advantages, such as deep data insights and improved automation, there are some challenges when building sustainable supervised learning models. The following are some of these challenges:

* Supervised learning models can require certain levels of expertise to structure accurately.
* Training supervised learning models can be very time intensive.
* Datasets can have a higher likelihood of human error, resulting in algorithms learning incorrectly.
* Unlike unsupervised learning models, supervised learning cannot cluster or classify data on its own.

---
## Reference <a class="anchor" id="Reference"></a>
1.Wikimedia Foundation. (2021, November 2). Gradient descent. Wikipedia. Retrieved December 13, 2021, from https://en.wikipedia.org/wiki/Gradient_descent. 
